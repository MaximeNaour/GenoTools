| Modèle/Méthode                   | Description                                                                                                               | Processus                                                                                          | Applications                                       | Avantages                                            | Inconvénients                                      | Indépendance des échantillons |
|----------------------------------|---------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|---------------------------------------------------|-----------------------------------------------------|--------------------------------------------------|-------------------------------|
| Algorithme de Metropolis-Hastings | Génère une chaîne de Markov avec une distribution stationnaire proportionnelle à la cible.                                | Propose de nouveaux états via une distribution de proposition; accepte ou rejette selon un critère basé sur la densité cible. | Inférence bayésienne, simulation physique.        | Simple, applicable à de nombreuses distributions.  | Convergence lente, besoin d'ajuster la distribution de proposition. | Dépendants                  |
| Échantillonnage de Gibbs         | MCMC échantillonnant chaque variable conditionnellement aux autres variables.                                             | Met à jour séquentiellement chaque variable en échantillonnant à partir de sa distribution conditionnelle complète.        | Modèles hiérarchiques, vision par ordinateur.      | Facile à implémenter si les conditionnelles sont analytiques. | Inefficace si les variables sont fortement corrélées. | Dépendants                  |
| Hamiltonian Monte Carlo (HMC)    | Utilise les gradients pour générer des propositions via une dynamique hamiltonienne.                                      | Intègre une dynamique hamiltonienne avec des variables auxiliaires pour mieux explorer l'espace des paramètres.            | Modèles complexes en statistique, apprentissage bayésien. | Convergence rapide, faible autocorrélation des échantillons. | Calcul des gradients requis, implémentation complexe. | Dépendants                  |
| Slice Sampling                   | Utilise une variable auxiliaire pour définir une "slice" de la distribution cible.                                       | Échantillonne uniformément dans une région définie par une valeur seuil, alternant entre la variable d'intérêt et la variable auxiliaire. | Modélisation statistique, optimisation.           | Pas besoin de distribution de proposition, adaptable. | Inefficace en haute dimension.                      | Dépendants                  |
| Reversible Jump MCMC             | Étend MCMC pour sauter entre des modèles de dimensions différentes, utile dans des modèles non paramétriques comme le processus de Dirichlet. | Permet de passer entre des espaces de paramètres de différentes dimensions en adaptant la probabilité d'acceptation, souvent en lien avec un processus de Dirichlet. | Sélection de modèles, génétique statistique, modèles non paramétriques. | Utile pour la sélection de modèles, inférences non paramétriques. | Implémentation complexe, convergence lente possible. | Dépendants                  |
| Markov Chain Quasi-Monte Carlo   | Combine des chaînes de Markov et des séquences quasi-Monte Carlo pour une convergence plus rapide.                        | Intègre des séquences à faible discrépance dans les échantillonneurs MCMC pour améliorer la couverture de l'espace des paramètres. | Simulation stochastique avancée, statistique computationnelle. | Réduction significative de la variance, convergence accélérée. | Implémentation complexe, nécessite une bonne connaissance théorique. | Dépendants                  |
| Importance Sampling              | Génère des échantillons indépendants pondérés par une distribution de proposition.                                       | Pondère les échantillons en fonction des ratios de densité cible/proposition pour estimer efficacement des intégrales complexes. | Estimation d'intégrales, finance, analyse de risques. | Échantillons indépendants, flexible pour des distributions complexes. | Inefficace si la proposition ne correspond pas bien à la cible. | Indépendants                |
| Méthode de rejet                 | Propose des valeurs à partir d'une distribution enveloppe, accepte ou rejette selon une probabilité.                     | Génère des échantillons à partir d'une enveloppe et accepte ceux qui satisfont un critère basé sur la densité cible.        | Génération de distributions complexes.            | Échantillons indépendants, concept simple.          | Inefficace si l'enveloppe diffère fortement de la cible. | Indépendants                |
| Sequential Monte Carlo (SMC)     | Utilise un ensemble de particules représentant la distribution cible, mises à jour séquentiellement.                     | Les particules évoluent dans le temps selon une séquence de distributions, avec un rééchantillonnage pour éviter la dégénérescence. | Filtrage de particules, navigation robotique.      | Efficace pour les systèmes dynamiques, traitement en ligne. | Coût élevé si de nombreuses particules sont nécessaires. | Dépendants                  |
| Méthodes de particules mean-field | Utilisent des particules interagissant avec des mesures empiriques pour approximer des distributions non linéaires.     | Les particules interagissent via une mesure empirique pour approximer des distributions complexes ou non linéaires.         | Filtrage séquentiel, inférence bayésienne.         | Adaptées aux modèles dynamiques non linéaires.     | Nécessitent un grand nombre de particules pour une précision élevée. | Dépendants                  |
| Processus de Dirichlet           | Processus stochastique pour modéliser des distributions sur des distributions, souvent utilisé avec le Reversible Jump MCMC. | Exploite des échantillonneurs comme Gibbs ou Metropolis-Hastings dans des modèles bayésiens non paramétriques pour inférer automatiquement le nombre de clusters. | Modèles non paramétriques, clustering adaptatif.   | Flexible, permet un nombre infini de clusters.      | Calculs intensifs, nécessite des échantillonneurs avancés. | Dépendants                  |
| Simple Monte Carlo               | Génère des échantillons indépendants pour approximer des espérances ou intégrales.                                      | Génère aléatoirement des points dans l'espace d'intégration, puis utilise leur moyenne pour estimer des intégrales ou des espérances. | Estimation d’espérances, simulation numérique.     | Échantillons indépendants, facile à implémenter.    | Inefficace pour des fonctions très complexes ou de haute dimension. | Indépendants                |
| Quasi-Monte Carlo                | Utilise des séquences à faible discrépance au lieu d'échantillons aléatoires.                                            | Utilise des séquences déterministes qui couvrent uniformément l'espace cible, améliorant la convergence des estimations.    | Finance, optimisation, simulation scientifique.    | Convergence plus rapide, meilleure couverture de l’espace cible. | Moins efficace en très haute dimension, implémentation complexe. | Indépendants                |
| Monte Carlo Tree Search (MCTS)   | Génère un arbre de recherche avec des simulations aléatoires pour estimer le potentiel des nœuds.                       | Combine un arbre de recherche avec des simulations Monte Carlo pour explorer les résultats possibles et sélectionner les meilleurs mouvements. | Jeux (Go, Havannah), algorithmes de décision.      | Efficace pour explorer des espaces de décision complexes. | Peut être coûteux en calcul pour des jeux très complexes. | Dépendants                  |
